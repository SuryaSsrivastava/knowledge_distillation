{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3dGA6QjGm-s"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/dataset/klimb_llm_optimization_challenge.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "b5kr_qoOG0tS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of train and test data\n",
        "train_dir = \"/content/klimb_llm_optimization_challenge/seg_train\"\n",
        "test_dir = \"/content/klimb_llm_optimization_challenge/seg_test\"\n",
        "\n",
        "# Data configs\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150\n"
      ],
      "metadata": {
        "id": "D7NcJHpSbwzy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "\ttrain_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMoKmCBWcMjl",
        "outputId": "11ef4f3a-835f-4734-806d-59655aa4a827"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14034 files belonging to 6 classes.\n",
            "Using 11228 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeTEpjhVcTNo",
        "outputId": "e022657f-e3f1-4aac-9907-c72ef6b02006"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 6 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the MASTER Model - using Transfer Learning\n",
        "# Here we are using ImageNet pre-trained model weights\n",
        "base_model = keras.applications.ResNet152(\n",
        "\t\tweights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "\t\tinput_shape=(img_height, img_width, 3),\n",
        "\t\tinclude_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "base_model.trainable = False\n",
        "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "# x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "model.compile(\n",
        "\t\toptimizer=keras.optimizers.Adam(),\n",
        "\t\tloss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\t\tmetrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGNeR245NdMc",
        "outputId": "12fe1901-370f-4e78-8394-0d34d8aba04e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " resnet152 (Functional)      (None, 5, 5, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d_5  (None, 2048)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 6)                 12294     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58383238 (222.71 MB)\n",
            "Trainable params: 12294 (48.02 KB)\n",
            "Non-trainable params: 58370944 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "model.fit(train_ds, epochs=epochs)\n",
        "\n",
        "# Generate results on test data\n",
        "results = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy with trained teacher model:{results[1]*100 :.2f} %\")"
      ],
      "metadata": {
        "id": "67rDMIOLG4tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5a230d-8db9-4cb9-c072-c824b9cc5f0c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.3041 - sparse_categorical_accuracy: 0.8959\n",
            "Epoch 2/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9163\n",
            "Epoch 3/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.1980 - sparse_categorical_accuracy: 0.9287\n",
            "Epoch 4/20\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 5/20\n",
            "351/351 [==============================] - 48s 138ms/step - loss: 0.1548 - sparse_categorical_accuracy: 0.9431\n",
            "Epoch 6/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9511\n",
            "Epoch 7/20\n",
            "351/351 [==============================] - 48s 137ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9570\n",
            "Epoch 8/20\n",
            "351/351 [==============================] - 49s 139ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9605\n",
            "Epoch 9/20\n",
            "351/351 [==============================] - 49s 139ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9651\n",
            "Epoch 10/20\n",
            "351/351 [==============================] - 48s 138ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9676\n",
            "Epoch 11/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.0958 - sparse_categorical_accuracy: 0.9668\n",
            "Epoch 12/20\n",
            "351/351 [==============================] - 48s 137ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 13/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9753\n",
            "Epoch 14/20\n",
            "351/351 [==============================] - 48s 138ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9754\n",
            "Epoch 15/20\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "Epoch 16/20\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9782\n",
            "Epoch 17/20\n",
            "351/351 [==============================] - 49s 139ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9820\n",
            "Epoch 18/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9786\n",
            "Epoch 19/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "351/351 [==============================] - 49s 141ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9832\n",
            "19/19 [==============================] - 7s 133ms/step - loss: 0.4169 - sparse_categorical_accuracy: 0.9067\n",
            "Test accuracy with trained teacher model:90.67 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### saving Teacher Model\n",
        "model = model  # Get model (Sequential, Functional Model, or Model subclass)\n",
        "model.save('/content/teacher_model.keras')  # The file needs to end with the .keras extension"
      ],
      "metadata": {
        "id": "S8b0Y9ttgrIP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It can be used to reconstruct the model identically.\n",
        "# reconstructed_model = keras.models.load_model(\"teacher_model.keras\")"
      ],
      "metadata": {
        "id": "tFgjrh0MhJC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Student Model\n",
        "# Create the student\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(150, 150, 3)),\n",
        "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Dropout(0.10),\n",
        "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(6),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")"
      ],
      "metadata": {
        "id": "X8zPxuN5dFcx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJEbHzW9sz2S",
        "outputId": "28500959-7432-4267-c0bb-e82e163048a2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 75, 75, 16)        448       \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 75, 75, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 75, 75, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 75, 75, 16)        0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 38, 38, 16)        2320      \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 23104)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 6)                 138630    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141398 (552.34 KB)\n",
            "Trainable params: 141398 (552.34 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone student for later comparison\n",
        "student_scratch = keras.models.clone_model(student)"
      ],
      "metadata": {
        "id": "bfouh9LQiyTC"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_loss(\n",
        "        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "    ):\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "        student_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "        distillation_loss = self.distillation_loss_fn(\n",
        "            tf.nn.softmax(teacher_pred / self.temperature, axis=1),\n",
        "            tf.nn.softmax(y_pred / self.temperature, axis=1),\n",
        "        ) * (self.temperature**2)\n",
        "\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "        return loss\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.student(x)"
      ],
      "metadata": {
        "id": "YYF0TcPJdFzD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=3,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(train_ds, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjnXLiCEkY8D",
        "outputId": "1da17f12-70a0-466d-d5f2-8025e083005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            " 98/351 [=======>......................] - ETA: 36s - sparse_categorical_accuracy: 0.1649"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate distilled model on test dataset\n",
        "distiller.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VtGynNL0pOC",
        "outputId": "46013a97-8b37-4f29-c1a9-e58775d21e27"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 3s 16ms/step - sparse_categorical_accuracy: 0.1483\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1483333259820938"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train student model for comparison\n",
        "student_scratch.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate student trained from scratch.\n",
        "student_scratch.fit(train_ds, epochs=8)\n",
        "student_scratch.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44axOYeIvJFD",
        "outputId": "24f566ef-c351-4c6a-8bf9-3645e55ba3a7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "351/351 [==============================] - 7s 18ms/step - loss: 6.2247 - sparse_categorical_accuracy: 0.6869\n",
            "Epoch 2/8\n",
            "351/351 [==============================] - 6s 16ms/step - loss: 3.4208 - sparse_categorical_accuracy: 0.7840\n",
            "Epoch 3/8\n",
            "351/351 [==============================] - 5s 14ms/step - loss: 2.1898 - sparse_categorical_accuracy: 0.8424\n",
            "Epoch 4/8\n",
            "351/351 [==============================] - 5s 14ms/step - loss: 2.0673 - sparse_categorical_accuracy: 0.8473\n",
            "Epoch 5/8\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 1.5406 - sparse_categorical_accuracy: 0.8766\n",
            "Epoch 6/8\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 1.3646 - sparse_categorical_accuracy: 0.8875\n",
            "Epoch 7/8\n",
            "351/351 [==============================] - 5s 14ms/step - loss: 1.5259 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 8/8\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 1.2095 - sparse_categorical_accuracy: 0.9045\n",
            "19/19 [==============================] - 1s 25ms/step - loss: 11.4496 - sparse_categorical_accuracy: 0.6017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.44959545135498, 0.6016666889190674]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Metrics Comparison"
      ],
      "metadata": {
        "id": "HP9xaZKMwSBP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p21dbBBUwWFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. **Model Size Ratio:** Ratio = (222.71 * 1024 KB) / 552.34 KB = 413x reduction in size\n",
        "2. **Parameter Ratio:** Ratio = 58383238 / 141398 = 412 times reduction in parameters\n",
        "3. **Accuracy:** Both of master and student model should provide accurate responses.\n",
        "4. **Latency:** Time taken from feeding an input (single image) to receiving an output (prediction). -> latency is reduced since parameters and size are less\n",
        "5. **End-to-End Functionality:** The entire pipeline, from the model building to the final prediction from both master and student models should be operational without any errors.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eHOUvVHbvr0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}